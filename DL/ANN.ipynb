{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1d1frU6kpzPPE8ZtOvbJyg3Oy5yr5jr3E",
      "authorship_tag": "ABX9TyMFYSeQvnIB01CYFFrS1R0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himu0023/GEN-AI/blob/main/DL/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xmeUzPIdjkQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/GenAi/DEEP LEARNING/Churn_Modelling.csv\")\n",
        "X = df.iloc[:,3:13].values\n",
        "y = df.iloc[:,13].values"
      ],
      "metadata": {
        "id": "Tf5JVj7IjsQT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "Yn2qiDvOkctK",
        "outputId": "cd78c07f-c707-4b38-8d3b-949ddb8d188d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber            int64\n",
              "CustomerId           int64\n",
              "Surname             object\n",
              "CreditScore          int64\n",
              "Geography           object\n",
              "Gender              object\n",
              "Age                float64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard            int64\n",
              "IsActiveMember       int64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surname</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geography</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETA2Y9IckeB9",
        "outputId": "7a2d06a2-6bc0-4bf1-9afd-ffa78627d275"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]],\n",
              "      shape=(10000, 10), dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYhqBhPpkqCh",
        "outputId": "e621c298-f77f-45bb-e54b-aa6195237143"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0], shape=(10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labellencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labellencoder_X_1.fit_transform(X[:, 1])\n",
        "labellencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labellencoder_X_2.fit_transform(X[:, 2])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cUHH0Bhk1_t",
        "outputId": "b066272c-04bd-4a99-bea9-c4e31cc34739"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], shape=(10000, 10), dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into Traning and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "h9A7i-WTlZN4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6aF3Uk2l62w",
        "outputId": "e839bda1-5fa7-460f-dce8-555589b9e8a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JrRPlHLl7mO",
        "outputId": "a58c2595-ec4d-407e-96f2-172380c0d802"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "U2gJeuFrl9oz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_preds = clf.predict(X_test)\n",
        "\n",
        "# Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_preds)\n",
        "print(cm)\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test, y_preds)\n",
        "print(f\"Accuracy of Decision Tree: {score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIU1hnt5mWGq",
        "outputId": "04be4756-5f53-4909-e5f1-d9b4beb89033"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1330  277]\n",
            " [ 194  199]]\n",
            "Accuracy of Decision Tree: 76.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=200)\n",
        "clf.fit(X_train, y_train)\n",
        "y_preds2 = clf.predict(X_test)\n",
        "\n",
        "# Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_preds)\n",
        "print(cm)\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test, y_preds2)\n",
        "print(f\"Accuracy of Random Forest: {score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYT_HmFmnzKF",
        "outputId": "7d4e33a1-8ae5-477d-cebc-376072805fa7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1330  277]\n",
            " [ 194  199]]\n",
            "Accuracy of Random Forest: 86.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN - Let's get started !!!"
      ],
      "metadata": {
        "id": "6xKnK7e7n-Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install keras\n",
        "# !pip install tensorflow"
      ],
      "metadata": {
        "id": "eg0oAS2Ppyz0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras Libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "_fezegOfp5Tv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initilising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# units : It's an art, comes by experience, input+output/2\n",
        "# kernel_initializer: how out weights are updated\n",
        "# relu activation function\n",
        "# Input_dim: input layer and the firest hidden layer\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer= 'uniform', activation = 'relu', input_dim = 10))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = 'relu'))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid')) # softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGh1dGStakP",
        "outputId": "702bd96d-eb36-4a5a-cb57-32a165b54241"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu4U97j3v5km",
        "outputId": "dbc1e151-ae68-477f-a18c-51631d9fdc67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy or sparse_categorical_crossentropy\n",
        "y_train[0]\n",
        "\n",
        "# Fitting the ANN to the Trainig set\n",
        "classifier.fit(X_train, y_train, batch_size=10, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50y6fC7Kv857",
        "outputId": "02e5f7b2-9938-4fcd-c18e-347d2670b405"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7908 - loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7930 - loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7936e0669700>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3 - Making prediction and evaluation the model\n",
        "# Predicting the test result\n",
        "\n",
        "y_pred_ann = classifier.predict(X_test)\n",
        "y_pred_ann = (y_pred_ann > 0.5)\n",
        "\n",
        "cm3 = confusion_matrix(y_test, y_pred_ann)\n",
        "print(cm3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGBvr8rhxZh7",
        "outputId": "dad6d66c-41af-41d5-8600-2ce9ca63437b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "[[1607    0]\n",
            " [ 393    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score3 = accuracy_score(y_test, y_pred_ann)\n",
        "print(f\"Accuracy of ANN: {score3*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa0ESa9D-5JN",
        "outputId": "f9ef84cd-ab30-455d-e3f5-884fe908e3dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of ANN: 80.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy from ANN: 80.35%\n",
        "\n",
        "# Conclusion:\n",
        "So, as we have already seen, by using 2 hidden layered ANN, we aren't able to get beyond 80% accuracy, of course we can get higher accuracy by increasing the epochs and doung some hyperparameter tuning, so on the other hand, the classical models can also be tuned further.\n",
        "\n",
        "Bottom line, always start with classical machine learning models, and of we aren't able to increase the performance, then move towards Deep Learning techniques."
      ],
      "metadata": {
        "id": "Nk-I2V_d8bBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting a single new observation\n",
        "\"\"\"Predict if the customer with the following information will leave the bank:\n",
        "Geography: France\n",
        "Credit Score: 600\n",
        "Gender: Male\n",
        "Age: 40\n",
        "Tenure: 3\n",
        "Balance: 60000\n",
        "Number of Products: 2\n",
        "Has Credit Card: Yes\n",
        "Is Active Member: Yes\n",
        "Estimated Salary: 50000\"\"\"\n",
        "\n",
        "new_data = np.array([[600, 0, 1, 40, 3, 60000, 2, 1, 1, 50000]])  # 2D\n",
        "new_data = sc.transform(new_data)\n",
        "new_prediction = classifier.predict(new_data)\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "new_prediction\n",
        "\n",
        "# Making the confusion matrix\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# cm = confusion_matrix(y_test, y_preds)\n",
        "# print(cm)"
      ],
      "metadata": {
        "id": "fBdlCrqJ-9zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509d4d96-2d47-4aa1-8719-7f016a6197b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scikeras\n"
      ],
      "metadata": {
        "id": "0mYQk56NC7TE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Keras / TensorFlow\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "# X = df.iloc[:, 3:13].values   # 10 input columns\n",
        "# y = df.iloc[:, 13].values     # target column\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# ---------------------------\n",
        "# Preprocessing\n",
        "# ---------------------------\n",
        "categorical_features = [1, 2]   # Geography, Gender\n",
        "numeric_features = [0, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_transformer, numeric_features),\n",
        "    (\"cat\", categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# Model builder\n",
        "# ---------------------------\n",
        "def build_classifier(meta):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=6, activation=\"relu\", input_dim=meta[\"n_features_in_\"]))\n",
        "    model.add(Dense(units=6, activation=\"relu\"))\n",
        "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "classifier = KerasClassifier(\n",
        "    model=build_classifier,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Full pipeline\n",
        "# ---------------------------\n",
        "clf = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"nn\", classifier)\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# Verify preprocessing\n",
        "# ---------------------------\n",
        "Xt = preprocessor.fit_transform(X)\n",
        "print(\"Any NaNs left?\", np.isnan(Xt).any())   # must be False\n",
        "print(\"Shape after preprocess:\", Xt.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# Cross-validation\n",
        "# ---------------------------\n",
        "accuracies = cross_val_score(clf, X, y, cv=10, n_jobs=-1, error_score=\"raise\")\n",
        "\n",
        "print(\"Mean accuracy:\", accuracies.mean())\n",
        "print(\"Std deviation:\", accuracies.std())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDsRgcq8-s7I",
        "outputId": "e532552b-e042-4e89-cb9a-2306ea1b73c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any NaNs left? False\n",
            "Shape after preprocess: (10000, 14)\n",
            "Mean accuracy: 0.8523\n",
            "Std deviation: 0.011393419153177866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More robust version with additional checks\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Keras / TensorFlow\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# ---------------------------\n",
        "# Data preparation with checks\n",
        "# ---------------------------\n",
        "X = df.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1)\n",
        "y = df['Exited']\n",
        "\n",
        "print(\"Data shapes:\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "print(\"\\nData types:\")\n",
        "print(X.dtypes)\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# ---------------------------\n",
        "# Preprocessing\n",
        "# ---------------------------\n",
        "categorical_features = ['Geography', 'Gender']\n",
        "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
        "                   'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
        "\n",
        "# Use simpler imputers that are more robust\n",
        "numeric_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # More robust than mean\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),  # More robust\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_transformer, numeric_features),\n",
        "    (\"cat\", categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# Test preprocessing first\n",
        "# ---------------------------\n",
        "print(\"\\nTesting preprocessing...\")\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "print(f\"Transformed shape: {X_transformed.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Model builder\n",
        "# ---------------------------\n",
        "def build_classifier(meta, optimizer=\"adam\", units1=6, units2=6):\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=units1, activation=\"relu\", input_dim=n_features_in_))\n",
        "    model.add(Dense(units=units2, activation=\"relu\"))\n",
        "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Start with simpler grid search\n",
        "# ---------------------------\n",
        "classifier = KerasClassifier(\n",
        "    model=build_classifier,\n",
        "    epochs=10,  # Start with fewer epochs for testing\n",
        "    batch_size=32,\n",
        "    verbose=0,\n",
        "    optimizer=\"adam\"\n",
        ")\n",
        "\n",
        "clf = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"nn\", classifier)\n",
        "])\n",
        "\n",
        "# Start with a smaller grid for testing\n",
        "simple_param_grid = {\n",
        "    \"nn__epochs\": [10, 20],\n",
        "    \"nn__batch_size\": [32, 64],\n",
        "    \"nn__optimizer\": [\"adam\"],\n",
        "    \"nn__model__units1\": [6],\n",
        "    \"nn__model__units2\": [6]\n",
        "}\n",
        "\n",
        "print(\"\\nStarting grid search with simple parameters...\")\n",
        "grid = GridSearchCV(estimator=clf,\n",
        "                    param_grid=simple_param_grid,\n",
        "                    cv=2,  # Fewer folds for testing\n",
        "                    n_jobs=1,\n",
        "                    scoring=\"accuracy\",\n",
        "                    verbose=1)\n",
        "\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "print(\"Best score:\", grid_result.best_score_)\n",
        "print(\"Best params:\", grid_result.best_params_)\n",
        "\n",
        "# If successful, run the full grid search\n",
        "print(\"\\nStarting full grid search...\")\n",
        "full_param_grid = {\n",
        "    \"nn__epochs\": [50, 100],\n",
        "    \"nn__batch_size\": [10, 25],\n",
        "    \"nn__optimizer\": [\"adam\", \"rmsprop\"],\n",
        "    \"nn__model__units1\": [6, 12],\n",
        "    \"nn__model__units2\": [6, 12]\n",
        "}\n",
        "\n",
        "full_grid = GridSearchCV(estimator=clf,\n",
        "                         param_grid=full_param_grid,\n",
        "                         cv=3,\n",
        "                         n_jobs=-1,  # Use all cores\n",
        "                         scoring=\"accuracy\",\n",
        "                         verbose=1)\n",
        "\n",
        "full_grid_result = full_grid.fit(X, y)\n",
        "\n",
        "print(\"Full grid search - Best score:\", full_grid_result.best_score_)\n",
        "print(\"Full grid search - Best params:\", full_grid_result.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_nOj30bdILN",
        "outputId": "3140e9a0-1b12-4dd6-eece-3692b88b2655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes:\n",
            "X shape: (10000, 10)\n",
            "y shape: (10000,)\n",
            "\n",
            "Data types:\n",
            "CreditScore          int64\n",
            "Geography           object\n",
            "Gender              object\n",
            "Age                float64\n",
            "Tenure               int64\n",
            "Balance            float64\n",
            "NumOfProducts        int64\n",
            "HasCrCard            int64\n",
            "IsActiveMember       int64\n",
            "EstimatedSalary    float64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "CreditScore          0\n",
            "Geography            0\n",
            "Gender              54\n",
            "Age                300\n",
            "Tenure               0\n",
            "Balance              0\n",
            "NumOfProducts        0\n",
            "HasCrCard            0\n",
            "IsActiveMember       0\n",
            "EstimatedSalary      0\n",
            "dtype: int64\n",
            "\n",
            "Testing preprocessing...\n",
            "Transformed shape: (10000, 14)\n",
            "\n",
            "Starting grid search with simple parameters...\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.8454\n",
            "Best params: {'nn__batch_size': 32, 'nn__epochs': 10, 'nn__model__units1': 6, 'nn__model__units2': 6, 'nn__optimizer': 'adam'}\n",
            "\n",
            "Starting full grid search...\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KWR-QFbT1q9"
      },
      "source": [
        "#Improvising the ANN - Hyper parameter optimization, adding more hyperparameters\n",
        "######################################\n",
        "######################################\n",
        "######################################\n",
        "######################################\n",
        "#TO DO TASK\n",
        "######################################\n",
        "######################################\n",
        "######################################\n",
        "######################################\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier(loss, optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "parameters = {'batch_size': [10,20, 30, 50],\n",
        "              'epochs': [10,50,100,200],\n",
        "              'loss': ['binary_crossentropy', 'categorical_crossentropy'],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', n_jobs = -1, cv = 10)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuple1 = ([2,3,4],6,7)"
      ],
      "metadata": {
        "id": "ptBZDiXfJr3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuple1[0][1]=5"
      ],
      "metadata": {
        "id": "CG-AD44JJxZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuple1"
      ],
      "metadata": {
        "id": "mZdjkuAuJ1Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvising the performance of ANN\n",
        "\n",
        "1. Increasing the number of hidden layers\n",
        "2. Increasing the number of epochs\n",
        "3. Fine-tuning the parameters - optimizers, batch_size, epochs\n",
        "4. Dropout regularization: Dropout(0.25)\n",
        "\n",
        "Overfitting problem --> training accuracy increases, but test accuracy is low"
      ],
      "metadata": {
        "id": "syw31pp9cYaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C7PsnD_uI77l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLSMi8Am0UoFQFQOb9xArC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himu0023/GEN-AI/blob/main/NLP/LSMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "2guusC9FSDiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q_7tsm-KF7lM"
      },
      "outputs": [],
      "source": [
        "text =\"\"\"Data analysis is not just a mere process; it's a tool that empowers\n",
        "organizations to make informed decisions, predict trends, and improve operational efficiency.\n",
        "It's the backbone of strategic planning in businesses, governments, and other\n",
        "organizations.Consider some examples. Take, for instance, a leading e-commerce\n",
        "company. Through data analysis, the company can understand their customers'\n",
        "buying behavior, preferences, and patterns. They can then use this information\n",
        "to personalize customer experiences, forecast sales, and optimize marketing\n",
        "strategies, ultimately driving business growth and customer satisfaction.\n",
        "Another good example is the healthcare industry. Through data analysis,\n",
        "healthcare providers can predict disease outbreaks, improve patient care, and\n",
        "make informed decisions about treatment strategies. \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "P8fV4ZJwKgu6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "coiSx3RLKoMn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj7b7SklK0bp",
        "outputId": "d29140d1-2554-49de-c370-e57a1300a1a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('.'):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyE3nnbmK4IO",
        "outputId": "350a62a6-b45c-44b3-8ce0-ae09b89e7195"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28, 1, 15, 29, 30]\n",
            "[8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38, 9]\n",
            "[39, 40, 41]\n",
            "[42, 43, 44, 4, 45, 46, 47, 16]\n",
            "[17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1, 54]\n",
            "[55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67, 68, 69, 1, 18, 70]\n",
            "[71, 72, 73, 7, 5, 20, 74]\n",
            "[17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81, 19]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_squences=[]\n",
        "\n",
        "for sentence in text.split('.'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "      input_squences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "63I0gNlJLAMU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_squences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvjUe_YVMj8G",
        "outputId": "20952250-0d54-4929-8078-a3347bbbf29a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3],\n",
              " [2, 3, 7],\n",
              " [2, 3, 7, 21],\n",
              " [2, 3, 7, 21, 22],\n",
              " [2, 3, 7, 21, 22, 4],\n",
              " [2, 3, 7, 21, 22, 4, 23],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28, 1],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15,\n",
              "  29],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15,\n",
              "  29,\n",
              "  30],\n",
              " [8, 5],\n",
              " [8, 5, 31],\n",
              " [8, 5, 31, 32],\n",
              " [8, 5, 31, 32, 33],\n",
              " [8, 5, 31, 32, 33, 34],\n",
              " [8, 5, 31, 32, 33, 34, 35],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38, 9],\n",
              " [39, 40],\n",
              " [39, 40, 41],\n",
              " [42, 43],\n",
              " [42, 43, 44],\n",
              " [42, 43, 44, 4],\n",
              " [42, 43, 44, 4, 45],\n",
              " [42, 43, 44, 4, 45, 46],\n",
              " [42, 43, 44, 4, 45, 46, 47],\n",
              " [42, 43, 44, 4, 45, 46, 47, 16],\n",
              " [17, 2],\n",
              " [17, 2, 3],\n",
              " [17, 2, 3, 5],\n",
              " [17, 2, 3, 5, 16],\n",
              " [17, 2, 3, 5, 16, 6],\n",
              " [17, 2, 3, 5, 16, 6, 48],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1, 54],\n",
              " [55, 6],\n",
              " [55, 6, 56],\n",
              " [55, 6, 56, 57],\n",
              " [55, 6, 56, 57, 58],\n",
              " [55, 6, 56, 57, 58, 59],\n",
              " [55, 6, 56, 57, 58, 59, 10],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67, 68],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1,\n",
              "  18],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1,\n",
              "  18,\n",
              "  70],\n",
              " [71, 72],\n",
              " [71, 72, 73],\n",
              " [71, 72, 73, 7],\n",
              " [71, 72, 73, 7, 5],\n",
              " [71, 72, 73, 7, 5, 20],\n",
              " [71, 72, 73, 7, 5, 20, 74],\n",
              " [17, 2],\n",
              " [17, 2, 3],\n",
              " [17, 2, 3, 20],\n",
              " [17, 2, 3, 20, 75],\n",
              " [17, 2, 3, 20, 75, 6],\n",
              " [17, 2, 3, 20, 75, 6, 14],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81, 19]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_squences])"
      ],
      "metadata": {
        "id": "t5sYDOs5NETM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekX-d3N1NwRo",
        "outputId": "ea82c39a-ba2e-49b3-979d-66702ae97104"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "paded_input_squences = pad_sequences(input_squences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "hTdc0qUGN9Cz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paded_input_squences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ioLZ-4pOJdj",
        "outputId": "b58a19e6-d880-4ef5-f40e-2f5d7dd38ba1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  2,  3],\n",
              "       [ 0,  0,  0, ...,  2,  3,  7],\n",
              "       [ 0,  0,  0, ...,  3,  7, 21],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 12, 13, 80],\n",
              "       [ 0,  0,  0, ..., 13, 80, 81],\n",
              "       [ 0,  0,  0, ..., 80, 81, 19]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = paded_input_squences[:,:-1]\n",
        "y = paded_input_squences[:,-1]"
      ],
      "metadata": {
        "id": "ZvEb2CsaOUh7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOT4OWLFOuYw",
        "outputId": "c2ac9ac1-e4c1-4ec6-c8fe-ed3290341dd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  2],\n",
              "       [ 0,  0,  0, ...,  0,  2,  3],\n",
              "       [ 0,  0,  0, ...,  2,  3,  7],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 11, 12, 13],\n",
              "       [ 0,  0,  0, ..., 12, 13, 80],\n",
              "       [ 0,  0,  0, ..., 13, 80, 81]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHm1mdoSO34N",
        "outputId": "72ba7c34-e8eb-4532-8da2-fef1ec9b81c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  7, 21, 22,  4, 23, 24,  8,  4, 25, 26, 27,  9, 10, 11, 12, 13,\n",
              "       14, 28,  1, 15, 29, 30,  5, 31, 32, 33, 34, 35, 36, 37,  1, 38,  9,\n",
              "       40, 41, 43, 44,  4, 45, 46, 47, 16,  2,  3,  5, 16,  6, 48, 49, 50,\n",
              "       51, 52, 53,  1, 54,  6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63,  1,\n",
              "       64, 65, 19, 66, 67, 68, 69,  1, 18, 70, 72, 73,  7,  5, 20, 74,  2,\n",
              "        3, 20, 75,  6, 14, 76, 77, 15, 78, 79,  1, 11, 12, 13, 80, 81, 19],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4SyIJ7CO7Y9",
        "outputId": "392b7481-2a3f-4c01-c182-9ef1eb21b8dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'data': 2,\n",
              " 'analysis': 3,\n",
              " 'a': 4,\n",
              " 'the': 5,\n",
              " 'can': 6,\n",
              " 'is': 7,\n",
              " \"it's\": 8,\n",
              " 'organizations': 9,\n",
              " 'to': 10,\n",
              " 'make': 11,\n",
              " 'informed': 12,\n",
              " 'decisions': 13,\n",
              " 'predict': 14,\n",
              " 'improve': 15,\n",
              " 'company': 16,\n",
              " 'through': 17,\n",
              " 'customer': 18,\n",
              " 'strategies': 19,\n",
              " 'healthcare': 20,\n",
              " 'not': 21,\n",
              " 'just': 22,\n",
              " 'mere': 23,\n",
              " 'process': 24,\n",
              " 'tool': 25,\n",
              " 'that': 26,\n",
              " 'empowers': 27,\n",
              " 'trends': 28,\n",
              " 'operational': 29,\n",
              " 'efficiency': 30,\n",
              " 'backbone': 31,\n",
              " 'of': 32,\n",
              " 'strategic': 33,\n",
              " 'planning': 34,\n",
              " 'in': 35,\n",
              " 'businesses': 36,\n",
              " 'governments': 37,\n",
              " 'other': 38,\n",
              " 'consider': 39,\n",
              " 'some': 40,\n",
              " 'examples': 41,\n",
              " 'take': 42,\n",
              " 'for': 43,\n",
              " 'instance': 44,\n",
              " 'leading': 45,\n",
              " 'e': 46,\n",
              " 'commerce': 47,\n",
              " 'understand': 48,\n",
              " 'their': 49,\n",
              " \"customers'\": 50,\n",
              " 'buying': 51,\n",
              " 'behavior': 52,\n",
              " 'preferences': 53,\n",
              " 'patterns': 54,\n",
              " 'they': 55,\n",
              " 'then': 56,\n",
              " 'use': 57,\n",
              " 'this': 58,\n",
              " 'information': 59,\n",
              " 'personalize': 60,\n",
              " 'experiences': 61,\n",
              " 'forecast': 62,\n",
              " 'sales': 63,\n",
              " 'optimize': 64,\n",
              " 'marketing': 65,\n",
              " 'ultimately': 66,\n",
              " 'driving': 67,\n",
              " 'business': 68,\n",
              " 'growth': 69,\n",
              " 'satisfaction': 70,\n",
              " 'another': 71,\n",
              " 'good': 72,\n",
              " 'example': 73,\n",
              " 'industry': 74,\n",
              " 'providers': 75,\n",
              " 'disease': 76,\n",
              " 'outbreaks': 77,\n",
              " 'patient': 78,\n",
              " 'care': 79,\n",
              " 'about': 80,\n",
              " 'treatment': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "2gdF5DO3QbHw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vzzl5F2QzTw",
        "outputId": "97913704-8024-4775-d820-7660d2fc06b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFAyn1VQ3LM",
        "outputId": "9930e01e-b482-4512-df0d-bd8f3a507793"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "3bo10_-xQ41P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MavTWgsYfQX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "pznrlJG8RlC8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=83, output_dim=100))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(82, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EY2mnvBKR91Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=100,\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sAWjHZrYmNq",
        "outputId": "570ad9be-8662-4a55-9e70-428d5e7c821b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.0280 - loss: 4.4077 - val_accuracy: 0.0000e+00 - val_loss: 4.4082\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.0716 - loss: 4.3905 - val_accuracy: 0.0000e+00 - val_loss: 4.4069\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.0465 - loss: 4.3745 - val_accuracy: 0.0000e+00 - val_loss: 4.4048\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0559 - loss: 4.3433 - val_accuracy: 0.0000e+00 - val_loss: 4.4154\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.0459 - loss: 4.2687 - val_accuracy: 0.0000e+00 - val_loss: 4.5598\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.0280 - loss: 4.2360 - val_accuracy: 0.0000e+00 - val_loss: 4.6190\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0364 - loss: 4.1821 - val_accuracy: 0.0952 - val_loss: 4.6624\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0520 - loss: 4.1006 - val_accuracy: 0.0952 - val_loss: 4.7930\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1041 - loss: 4.0565 - val_accuracy: 0.0952 - val_loss: 4.9251\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.0862 - loss: 3.9681 - val_accuracy: 0.0952 - val_loss: 5.0392\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.0621 - loss: 3.8658 - val_accuracy: 0.0476 - val_loss: 5.1839\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0465 - loss: 3.7955 - val_accuracy: 0.0476 - val_loss: 5.1950\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0979 - loss: 3.6404 - val_accuracy: 0.0476 - val_loss: 5.3146\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0582 - loss: 3.5777 - val_accuracy: 0.0476 - val_loss: 5.4389\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0823 - loss: 3.4963 - val_accuracy: 0.1429 - val_loss: 5.4787\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.0728 - loss: 3.4637 - val_accuracy: 0.0476 - val_loss: 5.6331\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1041 - loss: 3.3849 - val_accuracy: 0.0952 - val_loss: 5.6666\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.1343 - loss: 3.2730 - val_accuracy: 0.0000e+00 - val_loss: 5.7719\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.1538 - loss: 3.2311 - val_accuracy: 0.0000e+00 - val_loss: 5.9045\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.1623 - loss: 3.1525 - val_accuracy: 0.0000e+00 - val_loss: 5.9726\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.1584 - loss: 3.0840 - val_accuracy: 0.0476 - val_loss: 6.0582\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1600 - loss: 3.0089 - val_accuracy: 0.0476 - val_loss: 6.1280\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2462 - loss: 2.9658 - val_accuracy: 0.0476 - val_loss: 6.2681\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.2462 - loss: 2.8948 - val_accuracy: 0.0476 - val_loss: 6.3701\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2569 - loss: 2.8171 - val_accuracy: 0.0476 - val_loss: 6.4492\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2703 - loss: 2.7170 - val_accuracy: 0.0476 - val_loss: 6.5309\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3314 - loss: 2.6805 - val_accuracy: 0.0476 - val_loss: 6.6542\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3665 - loss: 2.5140 - val_accuracy: 0.0000e+00 - val_loss: 6.6832\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.3453 - loss: 2.5228 - val_accuracy: 0.0000e+00 - val_loss: 6.7020\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4397 - loss: 2.4146 - val_accuracy: 0.0000e+00 - val_loss: 6.8164\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3928 - loss: 2.3698 - val_accuracy: 0.0000e+00 - val_loss: 6.8789\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4930 - loss: 2.2367 - val_accuracy: 0.0000e+00 - val_loss: 6.8749\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5093 - loss: 2.2827 - val_accuracy: 0.0000e+00 - val_loss: 6.9569\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5103 - loss: 2.1798 - val_accuracy: 0.0000e+00 - val_loss: 7.0641\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5847 - loss: 2.1031 - val_accuracy: 0.0000e+00 - val_loss: 7.0896\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6205 - loss: 2.0541 - val_accuracy: 0.0000e+00 - val_loss: 7.1089\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5965 - loss: 1.9916 - val_accuracy: 0.0476 - val_loss: 7.0751\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5518 - loss: 1.9925 - val_accuracy: 0.0000e+00 - val_loss: 7.0672\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6670 - loss: 1.8858 - val_accuracy: 0.0000e+00 - val_loss: 7.2369\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 0.6413 - loss: 1.8814 - val_accuracy: 0.0000e+00 - val_loss: 7.3290\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.6475 - loss: 1.7900 - val_accuracy: 0.0000e+00 - val_loss: 7.2908\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - accuracy: 0.6140 - loss: 1.8112 - val_accuracy: 0.0000e+00 - val_loss: 7.3043\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.6429 - loss: 1.6924 - val_accuracy: 0.0000e+00 - val_loss: 7.3554\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6596 - loss: 1.7161 - val_accuracy: 0.0000e+00 - val_loss: 7.4265\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6279 - loss: 1.7135 - val_accuracy: 0.0000e+00 - val_loss: 7.4344\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6693 - loss: 1.5589 - val_accuracy: 0.0000e+00 - val_loss: 7.4525\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7415 - loss: 1.5710 - val_accuracy: 0.0000e+00 - val_loss: 7.5102\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7766 - loss: 1.5014 - val_accuracy: 0.0476 - val_loss: 7.5693\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7190 - loss: 1.4769 - val_accuracy: 0.0476 - val_loss: 7.5032\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7437 - loss: 1.4307 - val_accuracy: 0.0476 - val_loss: 7.5487\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7376 - loss: 1.4590 - val_accuracy: 0.0000e+00 - val_loss: 7.6823\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7633 - loss: 1.3506 - val_accuracy: 0.0000e+00 - val_loss: 7.6445\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8315 - loss: 1.3485 - val_accuracy: 0.0000e+00 - val_loss: 7.6458\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8058 - loss: 1.3062 - val_accuracy: 0.0000e+00 - val_loss: 7.7330\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8058 - loss: 1.2840 - val_accuracy: 0.0000e+00 - val_loss: 7.7321\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8751 - loss: 1.1954 - val_accuracy: 0.0000e+00 - val_loss: 7.7508\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8383 - loss: 1.2457 - val_accuracy: 0.0000e+00 - val_loss: 7.8207\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8182 - loss: 1.2005 - val_accuracy: 0.0000e+00 - val_loss: 7.8233\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8423 - loss: 1.1569 - val_accuracy: 0.0000e+00 - val_loss: 7.8027\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9210 - loss: 1.0449 - val_accuracy: 0.0000e+00 - val_loss: 7.8513\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8836 - loss: 1.0924 - val_accuracy: 0.0000e+00 - val_loss: 7.9026\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8283 - loss: 1.0883 - val_accuracy: 0.0000e+00 - val_loss: 7.9366\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8819 - loss: 1.0752 - val_accuracy: 0.0000e+00 - val_loss: 7.9870\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9412 - loss: 0.9681 - val_accuracy: 0.0000e+00 - val_loss: 7.9655\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8859 - loss: 1.0032 - val_accuracy: 0.0000e+00 - val_loss: 8.0275\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9132 - loss: 0.9973 - val_accuracy: 0.0000e+00 - val_loss: 8.0861\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9317 - loss: 0.9927 - val_accuracy: 0.0000e+00 - val_loss: 8.0525\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9356 - loss: 0.9156 - val_accuracy: 0.0000e+00 - val_loss: 8.0858\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9457 - loss: 0.8755 - val_accuracy: 0.0000e+00 - val_loss: 8.1260\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9340 - loss: 0.8898 - val_accuracy: 0.0476 - val_loss: 8.1236\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9580 - loss: 0.9127 - val_accuracy: 0.0476 - val_loss: 8.0868\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9776 - loss: 0.8551 - val_accuracy: 0.0476 - val_loss: 8.1345\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9720 - loss: 0.8168 - val_accuracy: 0.0476 - val_loss: 8.1501\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9877 - loss: 0.7721 - val_accuracy: 0.0476 - val_loss: 8.1896\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9659 - loss: 0.8027 - val_accuracy: 0.0476 - val_loss: 8.1949\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9720 - loss: 0.7526 - val_accuracy: 0.0476 - val_loss: 8.1916\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9938 - loss: 0.7423 - val_accuracy: 0.0476 - val_loss: 8.2061\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9899 - loss: 0.7172 - val_accuracy: 0.0476 - val_loss: 8.2894\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9899 - loss: 0.7064 - val_accuracy: 0.0476 - val_loss: 8.2752\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9899 - loss: 0.7144 - val_accuracy: 0.0476 - val_loss: 8.2383\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9899 - loss: 0.6834 - val_accuracy: 0.0476 - val_loss: 8.3223\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9899 - loss: 0.6669 - val_accuracy: 0.0476 - val_loss: 8.3286\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.6446 - val_accuracy: 0.0476 - val_loss: 8.3162\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.6495 - val_accuracy: 0.0476 - val_loss: 8.3686\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.6159 - val_accuracy: 0.0476 - val_loss: 8.3401\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.6127 - val_accuracy: 0.0476 - val_loss: 8.3611\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.5891 - val_accuracy: 0.0476 - val_loss: 8.3830\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.5597 - val_accuracy: 0.0476 - val_loss: 8.4356\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.5904 - val_accuracy: 0.0476 - val_loss: 8.4124\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.5373 - val_accuracy: 0.0476 - val_loss: 8.4305\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9938 - loss: 0.5667 - val_accuracy: 0.0476 - val_loss: 8.5248\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.5269 - val_accuracy: 0.0476 - val_loss: 8.4560\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9821 - loss: 0.5397 - val_accuracy: 0.0476 - val_loss: 8.5399\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.5288 - val_accuracy: 0.0476 - val_loss: 8.4965\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.4848 - val_accuracy: 0.0476 - val_loss: 8.5077\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.4983 - val_accuracy: 0.0476 - val_loss: 8.5337\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.4648 - val_accuracy: 0.0476 - val_loss: 8.5742\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.4701 - val_accuracy: 0.0476 - val_loss: 8.5965\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.4582 - val_accuracy: 0.0476 - val_loss: 8.5674\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.4466 - val_accuracy: 0.0476 - val_loss: 8.6004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "X3FrDLz5UDAa",
        "outputId": "a51a5aed-7766-445a-fd41-848fee5a7258"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m8,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)             │        \u001b[38;5;34m12,382\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,382</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m513,848\u001b[0m (1.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513,848</span> (1.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m171,282\u001b[0m (669.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171,282</span> (669.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m342,566\u001b[0m (1.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,566</span> (1.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Test the model*"
      ],
      "metadata": {
        "id": "JG8DAXx3UGBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2= \"Data\"\n",
        "\n",
        "# Tokenizer\n",
        "token_text = tokenizer.texts_to_sequences([text2])[0]\n",
        "\n",
        "# Padding\n",
        "padded_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "# Predict\n",
        "predicted = model.predict(padded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdT63P_FcBGz",
        "outputId": "714f1237-13d2-4bee-87fa-0f4fb0be6374"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgSucah9cwsy",
        "outputId": "bb58966a-0a73-4183-9fc4-a39ea09a8b84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.88364190e-05, 2.22993942e-04, 1.38369948e-01, 9.64757130e-02,\n",
              "        5.87969180e-03, 5.19959405e-02, 4.74274121e-02, 2.55060732e-01,\n",
              "        4.90742037e-04, 3.12396951e-05, 1.30378653e-03, 3.04813730e-04,\n",
              "        3.80644546e-04, 1.66524420e-04, 8.15119594e-04, 4.11156914e-04,\n",
              "        2.67728418e-03, 2.24418964e-05, 1.71090782e-04, 3.92258298e-05,\n",
              "        2.86592934e-02, 2.87676416e-02, 8.07307754e-03, 2.07338668e-03,\n",
              "        8.55539227e-04, 1.62737022e-04, 4.05539831e-05, 1.97443020e-04,\n",
              "        2.43400118e-05, 9.68583772e-05, 4.56990201e-05, 3.15204449e-02,\n",
              "        1.57076549e-02, 6.35719334e-05, 9.49356181e-04, 6.04377012e-04,\n",
              "        3.16548918e-04, 5.19369496e-05, 4.81487572e-04, 4.61122072e-05,\n",
              "        4.65282165e-02, 4.11479808e-02, 2.49784607e-05, 2.89644562e-02,\n",
              "        2.32410748e-02, 3.32781044e-03, 4.15076938e-05, 5.97851875e-04,\n",
              "        7.36574060e-04, 5.03608608e-04, 7.50906547e-05, 1.03116610e-04,\n",
              "        1.79585943e-04, 2.97968625e-04, 1.52115943e-04, 3.48589092e-05,\n",
              "        1.05860215e-02, 2.01955694e-03, 8.25203606e-04, 2.16844914e-04,\n",
              "        4.77959366e-05, 8.21621943e-05, 3.60732738e-05, 2.29039342e-05,\n",
              "        4.66405945e-05, 4.80858907e-05, 5.81821005e-05, 2.95632472e-05,\n",
              "        5.64090733e-05, 2.03539948e-05, 8.36898266e-07, 2.97707156e-05,\n",
              "        1.12740397e-01, 4.42055753e-05, 2.10905564e-03, 3.34362732e-03,\n",
              "        6.79268633e-05, 2.50736048e-04, 1.06693944e-04, 1.53659144e-04,\n",
              "        5.41153859e-05, 3.28838287e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qt6xxkFc1FG",
        "outputId": "2f330b9a-7977-47d9-ac3a-a36bceddbd8e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk_3HbuWdAQS",
        "outputId": "1f8c9cd4-7734-48a1-e322-e3d099399e62"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'data': 2,\n",
              " 'analysis': 3,\n",
              " 'a': 4,\n",
              " 'the': 5,\n",
              " 'can': 6,\n",
              " 'is': 7,\n",
              " \"it's\": 8,\n",
              " 'organizations': 9,\n",
              " 'to': 10,\n",
              " 'make': 11,\n",
              " 'informed': 12,\n",
              " 'decisions': 13,\n",
              " 'predict': 14,\n",
              " 'improve': 15,\n",
              " 'company': 16,\n",
              " 'through': 17,\n",
              " 'customer': 18,\n",
              " 'strategies': 19,\n",
              " 'healthcare': 20,\n",
              " 'not': 21,\n",
              " 'just': 22,\n",
              " 'mere': 23,\n",
              " 'process': 24,\n",
              " 'tool': 25,\n",
              " 'that': 26,\n",
              " 'empowers': 27,\n",
              " 'trends': 28,\n",
              " 'operational': 29,\n",
              " 'efficiency': 30,\n",
              " 'backbone': 31,\n",
              " 'of': 32,\n",
              " 'strategic': 33,\n",
              " 'planning': 34,\n",
              " 'in': 35,\n",
              " 'businesses': 36,\n",
              " 'governments': 37,\n",
              " 'other': 38,\n",
              " 'consider': 39,\n",
              " 'some': 40,\n",
              " 'examples': 41,\n",
              " 'take': 42,\n",
              " 'for': 43,\n",
              " 'instance': 44,\n",
              " 'leading': 45,\n",
              " 'e': 46,\n",
              " 'commerce': 47,\n",
              " 'understand': 48,\n",
              " 'their': 49,\n",
              " \"customers'\": 50,\n",
              " 'buying': 51,\n",
              " 'behavior': 52,\n",
              " 'preferences': 53,\n",
              " 'patterns': 54,\n",
              " 'they': 55,\n",
              " 'then': 56,\n",
              " 'use': 57,\n",
              " 'this': 58,\n",
              " 'information': 59,\n",
              " 'personalize': 60,\n",
              " 'experiences': 61,\n",
              " 'forecast': 62,\n",
              " 'sales': 63,\n",
              " 'optimize': 64,\n",
              " 'marketing': 65,\n",
              " 'ultimately': 66,\n",
              " 'driving': 67,\n",
              " 'business': 68,\n",
              " 'growth': 69,\n",
              " 'satisfaction': 70,\n",
              " 'another': 71,\n",
              " 'good': 72,\n",
              " 'example': 73,\n",
              " 'industry': 74,\n",
              " 'providers': 75,\n",
              " 'disease': 76,\n",
              " 'outbreaks': 77,\n",
              " 'patient': 78,\n",
              " 'care': 79,\n",
              " 'about': 80,\n",
              " 'treatment': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == np.argmax(predicted):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqQbe-p-dTv5",
        "outputId": "7f2a8c39-7c2a-44ad-feef-aa525758dd64"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3= \"Data analysis is not just a mere process; it's a tool that empowers organizations to make informed decisions,\"\n",
        "\n",
        "# Tokenizer\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "\n",
        "# Padding\n",
        "padded_text = pad_sequences([token_text3], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "# Predict\n",
        "predicted = model.predict(padded_text)\n",
        "\n",
        "pos = np.argmax(predicted)\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == np.argmax(predicted):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNwSUQOHeCv5",
        "outputId": "1c90b7f4-d72c-4481-b46d-f71dfa382a9f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Improvements:\n",
        "1. Increasing the LSTM units\n",
        "2. Increasing the Dense layers\n",
        "3. Increasing the Data\n",
        "4. Using a pre-treained model on larger corpus of data\n",
        "5. Hyper parameter optimization"
      ],
      "metadata": {
        "id": "RPIJfyMffb9K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00VQ2Qtugq31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
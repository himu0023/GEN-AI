{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4/F/kgVwgN/Mj8JtA0JGO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "2guusC9FSDiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_7tsm-KF7lM"
      },
      "outputs": [],
      "source": [
        "text =\"\"\"Data analysis is not just a mere process; it's a tool that empowers\n",
        "organizations to make informed decisions, predict trends, and improve operational efficiency.\n",
        "It's the backbone of strategic planning in businesses, governments, and other\n",
        "organizations.Consider some examples. Take, for instance, a leading e-commerce\n",
        "company. Through data analysis, the company can understand their customers'\n",
        "buying behavior, preferences, and patterns. They can then use this information\n",
        "to personalize customer experiences, forecast sales, and optimize marketing\n",
        "strategies, ultimately driving business growth and customer satisfaction.\n",
        "Another good example is the healthcare industry. Through data analysis,\n",
        "healthcare providers can predict disease outbreaks, improve patient care, and\n",
        "make informed decisions about treatment strategies. \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "P8fV4ZJwKgu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "coiSx3RLKoMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj7b7SklK0bp",
        "outputId": "30c40f2e-a3b3-46f9-a18e-f52dc286e0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('.'):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyE3nnbmK4IO",
        "outputId": "b2c024e3-b17f-4b1a-d853-59eed075fca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28, 1, 15, 29, 30]\n",
            "[8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38, 9]\n",
            "[39, 40, 41]\n",
            "[42, 43, 44, 4, 45, 46, 47, 16]\n",
            "[17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1, 54]\n",
            "[55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67, 68, 69, 1, 18, 70]\n",
            "[71, 72, 73, 7, 5, 20, 74]\n",
            "[17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81, 19]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_squences=[]\n",
        "\n",
        "for sentence in text.split('.'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "      input_squences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "63I0gNlJLAMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_squences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvjUe_YVMj8G",
        "outputId": "12c1b029-78ae-4d35-961b-e772505bc959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3],\n",
              " [2, 3, 7],\n",
              " [2, 3, 7, 21],\n",
              " [2, 3, 7, 21, 22],\n",
              " [2, 3, 7, 21, 22, 4],\n",
              " [2, 3, 7, 21, 22, 4, 23],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28],\n",
              " [2, 3, 7, 21, 22, 4, 23, 24, 8, 4, 25, 26, 27, 9, 10, 11, 12, 13, 14, 28, 1],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15,\n",
              "  29],\n",
              " [2,\n",
              "  3,\n",
              "  7,\n",
              "  21,\n",
              "  22,\n",
              "  4,\n",
              "  23,\n",
              "  24,\n",
              "  8,\n",
              "  4,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  28,\n",
              "  1,\n",
              "  15,\n",
              "  29,\n",
              "  30],\n",
              " [8, 5],\n",
              " [8, 5, 31],\n",
              " [8, 5, 31, 32],\n",
              " [8, 5, 31, 32, 33],\n",
              " [8, 5, 31, 32, 33, 34],\n",
              " [8, 5, 31, 32, 33, 34, 35],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38],\n",
              " [8, 5, 31, 32, 33, 34, 35, 36, 37, 1, 38, 9],\n",
              " [39, 40],\n",
              " [39, 40, 41],\n",
              " [42, 43],\n",
              " [42, 43, 44],\n",
              " [42, 43, 44, 4],\n",
              " [42, 43, 44, 4, 45],\n",
              " [42, 43, 44, 4, 45, 46],\n",
              " [42, 43, 44, 4, 45, 46, 47],\n",
              " [42, 43, 44, 4, 45, 46, 47, 16],\n",
              " [17, 2],\n",
              " [17, 2, 3],\n",
              " [17, 2, 3, 5],\n",
              " [17, 2, 3, 5, 16],\n",
              " [17, 2, 3, 5, 16, 6],\n",
              " [17, 2, 3, 5, 16, 6, 48],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1],\n",
              " [17, 2, 3, 5, 16, 6, 48, 49, 50, 51, 52, 53, 1, 54],\n",
              " [55, 6],\n",
              " [55, 6, 56],\n",
              " [55, 6, 56, 57],\n",
              " [55, 6, 56, 57, 58],\n",
              " [55, 6, 56, 57, 58, 59],\n",
              " [55, 6, 56, 57, 58, 59, 10],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67],\n",
              " [55, 6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63, 1, 64, 65, 19, 66, 67, 68],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1,\n",
              "  18],\n",
              " [55,\n",
              "  6,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  10,\n",
              "  60,\n",
              "  18,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  1,\n",
              "  64,\n",
              "  65,\n",
              "  19,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  1,\n",
              "  18,\n",
              "  70],\n",
              " [71, 72],\n",
              " [71, 72, 73],\n",
              " [71, 72, 73, 7],\n",
              " [71, 72, 73, 7, 5],\n",
              " [71, 72, 73, 7, 5, 20],\n",
              " [71, 72, 73, 7, 5, 20, 74],\n",
              " [17, 2],\n",
              " [17, 2, 3],\n",
              " [17, 2, 3, 20],\n",
              " [17, 2, 3, 20, 75],\n",
              " [17, 2, 3, 20, 75, 6],\n",
              " [17, 2, 3, 20, 75, 6, 14],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81],\n",
              " [17, 2, 3, 20, 75, 6, 14, 76, 77, 15, 78, 79, 1, 11, 12, 13, 80, 81, 19]]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_squences])"
      ],
      "metadata": {
        "id": "t5sYDOs5NETM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekX-d3N1NwRo",
        "outputId": "9a2653cd-e634-4301-bd5e-427a3c63607f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "paded_input_squences = pad_sequences(input_squences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "hTdc0qUGN9Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paded_input_squences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ioLZ-4pOJdj",
        "outputId": "3ed0e6af-1900-432a-bf60-a2db9ebed73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  2,  3],\n",
              "       [ 0,  0,  0, ...,  2,  3,  7],\n",
              "       [ 0,  0,  0, ...,  3,  7, 21],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 12, 13, 80],\n",
              "       [ 0,  0,  0, ..., 13, 80, 81],\n",
              "       [ 0,  0,  0, ..., 80, 81, 19]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = paded_input_squences[:,:-1]\n",
        "y = paded_input_squences[:,-1]"
      ],
      "metadata": {
        "id": "ZvEb2CsaOUh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOT4OWLFOuYw",
        "outputId": "01d413bc-1a42-477e-ad46-2be83081ddcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  2],\n",
              "       [ 0,  0,  0, ...,  0,  2,  3],\n",
              "       [ 0,  0,  0, ...,  2,  3,  7],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 11, 12, 13],\n",
              "       [ 0,  0,  0, ..., 12, 13, 80],\n",
              "       [ 0,  0,  0, ..., 13, 80, 81]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHm1mdoSO34N",
        "outputId": "c6116e8b-29dc-4242-8322-e4eeae3f8a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  7, 21, 22,  4, 23, 24,  8,  4, 25, 26, 27,  9, 10, 11, 12, 13,\n",
              "       14, 28,  1, 15, 29, 30,  5, 31, 32, 33, 34, 35, 36, 37,  1, 38,  9,\n",
              "       40, 41, 43, 44,  4, 45, 46, 47, 16,  2,  3,  5, 16,  6, 48, 49, 50,\n",
              "       51, 52, 53,  1, 54,  6, 56, 57, 58, 59, 10, 60, 18, 61, 62, 63,  1,\n",
              "       64, 65, 19, 66, 67, 68, 69,  1, 18, 70, 72, 73,  7,  5, 20, 74,  2,\n",
              "        3, 20, 75,  6, 14, 76, 77, 15, 78, 79,  1, 11, 12, 13, 80, 81, 19],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4SyIJ7CO7Y9",
        "outputId": "a4aea8cf-eb65-4140-d1ee-07630469946c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'data': 2,\n",
              " 'analysis': 3,\n",
              " 'a': 4,\n",
              " 'the': 5,\n",
              " 'can': 6,\n",
              " 'is': 7,\n",
              " \"it's\": 8,\n",
              " 'organizations': 9,\n",
              " 'to': 10,\n",
              " 'make': 11,\n",
              " 'informed': 12,\n",
              " 'decisions': 13,\n",
              " 'predict': 14,\n",
              " 'improve': 15,\n",
              " 'company': 16,\n",
              " 'through': 17,\n",
              " 'customer': 18,\n",
              " 'strategies': 19,\n",
              " 'healthcare': 20,\n",
              " 'not': 21,\n",
              " 'just': 22,\n",
              " 'mere': 23,\n",
              " 'process': 24,\n",
              " 'tool': 25,\n",
              " 'that': 26,\n",
              " 'empowers': 27,\n",
              " 'trends': 28,\n",
              " 'operational': 29,\n",
              " 'efficiency': 30,\n",
              " 'backbone': 31,\n",
              " 'of': 32,\n",
              " 'strategic': 33,\n",
              " 'planning': 34,\n",
              " 'in': 35,\n",
              " 'businesses': 36,\n",
              " 'governments': 37,\n",
              " 'other': 38,\n",
              " 'consider': 39,\n",
              " 'some': 40,\n",
              " 'examples': 41,\n",
              " 'take': 42,\n",
              " 'for': 43,\n",
              " 'instance': 44,\n",
              " 'leading': 45,\n",
              " 'e': 46,\n",
              " 'commerce': 47,\n",
              " 'understand': 48,\n",
              " 'their': 49,\n",
              " \"customers'\": 50,\n",
              " 'buying': 51,\n",
              " 'behavior': 52,\n",
              " 'preferences': 53,\n",
              " 'patterns': 54,\n",
              " 'they': 55,\n",
              " 'then': 56,\n",
              " 'use': 57,\n",
              " 'this': 58,\n",
              " 'information': 59,\n",
              " 'personalize': 60,\n",
              " 'experiences': 61,\n",
              " 'forecast': 62,\n",
              " 'sales': 63,\n",
              " 'optimize': 64,\n",
              " 'marketing': 65,\n",
              " 'ultimately': 66,\n",
              " 'driving': 67,\n",
              " 'business': 68,\n",
              " 'growth': 69,\n",
              " 'satisfaction': 70,\n",
              " 'another': 71,\n",
              " 'good': 72,\n",
              " 'example': 73,\n",
              " 'industry': 74,\n",
              " 'providers': 75,\n",
              " 'disease': 76,\n",
              " 'outbreaks': 77,\n",
              " 'patient': 78,\n",
              " 'care': 79,\n",
              " 'about': 80,\n",
              " 'treatment': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "2gdF5DO3QbHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vzzl5F2QzTw",
        "outputId": "62ca9dcd-ab59-4083-fc18-43de7de42b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFAyn1VQ3LM",
        "outputId": "841fbd56-1d46-4e9a-ab8a-912a397d7903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "3bo10_-xQ41P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MavTWgsYfQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "pznrlJG8RlC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=83, output_dim=100))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(82, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EY2mnvBKR91Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=100,\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sAWjHZrYmNq",
        "outputId": "35fb2e4f-c26a-41eb-e9ec-c049eef8d2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.0179 - loss: 4.4074 - val_accuracy: 0.0476 - val_loss: 4.4067\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0924 - loss: 4.3910 - val_accuracy: 0.0476 - val_loss: 4.4048\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1002 - loss: 4.3734 - val_accuracy: 0.0000e+00 - val_loss: 4.4014\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0699 - loss: 4.3338 - val_accuracy: 0.0000e+00 - val_loss: 4.4167\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0403 - loss: 4.2595 - val_accuracy: 0.0000e+00 - val_loss: 4.5663\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.0559 - loss: 4.1980 - val_accuracy: 0.0476 - val_loss: 4.6469\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0839 - loss: 4.1907 - val_accuracy: 0.0952 - val_loss: 4.5558\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0481 - loss: 4.1267 - val_accuracy: 0.0952 - val_loss: 4.5966\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.0520 - loss: 4.0540 - val_accuracy: 0.0952 - val_loss: 4.7622\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1002 - loss: 3.9691 - val_accuracy: 0.0476 - val_loss: 4.8913\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0985 - loss: 3.9220 - val_accuracy: 0.0952 - val_loss: 4.7870\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1320 - loss: 3.8388 - val_accuracy: 0.0952 - val_loss: 4.9391\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1080 - loss: 3.7201 - val_accuracy: 0.0476 - val_loss: 5.1029\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1197 - loss: 3.6126 - val_accuracy: 0.0952 - val_loss: 5.0434\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.1242 - loss: 3.5459 - val_accuracy: 0.0952 - val_loss: 5.1365\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1080 - loss: 3.4909 - val_accuracy: 0.0476 - val_loss: 5.2915\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1298 - loss: 3.4062 - val_accuracy: 0.0476 - val_loss: 5.3505\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1288 - loss: 3.3200 - val_accuracy: 0.0476 - val_loss: 5.4476\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1779 - loss: 3.2167 - val_accuracy: 0.0952 - val_loss: 5.5991\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1678 - loss: 3.1439 - val_accuracy: 0.0476 - val_loss: 5.6681\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2205 - loss: 3.0984 - val_accuracy: 0.0476 - val_loss: 5.7289\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2088 - loss: 3.0163 - val_accuracy: 0.0476 - val_loss: 5.8572\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2384 - loss: 2.9185 - val_accuracy: 0.0952 - val_loss: 5.9739\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2686 - loss: 2.8940 - val_accuracy: 0.0476 - val_loss: 6.0545\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3161 - loss: 2.7574 - val_accuracy: 0.0000e+00 - val_loss: 6.1424\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3083 - loss: 2.6813 - val_accuracy: 0.0000e+00 - val_loss: 6.2650\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3581 - loss: 2.6174 - val_accuracy: 0.0000e+00 - val_loss: 6.3790\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3408 - loss: 2.5975 - val_accuracy: 0.0000e+00 - val_loss: 6.3755\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4101 - loss: 2.4913 - val_accuracy: 0.0000e+00 - val_loss: 6.5306\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.4114 - loss: 2.4304 - val_accuracy: 0.0000e+00 - val_loss: 6.5711\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.4868 - loss: 2.3529 - val_accuracy: 0.0000e+00 - val_loss: 6.5391\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.4796 - loss: 2.3177 - val_accuracy: 0.0000e+00 - val_loss: 6.6723\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.4634 - loss: 2.2408 - val_accuracy: 0.0000e+00 - val_loss: 6.7022\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.4969 - loss: 2.1286 - val_accuracy: 0.0000e+00 - val_loss: 6.6892\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5171 - loss: 2.0056 - val_accuracy: 0.0000e+00 - val_loss: 6.7969\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5646 - loss: 1.9934 - val_accuracy: 0.0000e+00 - val_loss: 6.9337\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5847 - loss: 1.9324 - val_accuracy: 0.0000e+00 - val_loss: 6.9416\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5965 - loss: 1.8641 - val_accuracy: 0.0000e+00 - val_loss: 6.8648\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6257 - loss: 1.8888 - val_accuracy: 0.0000e+00 - val_loss: 7.1242\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6312 - loss: 1.8331 - val_accuracy: 0.0000e+00 - val_loss: 7.1475\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6872 - loss: 1.7162 - val_accuracy: 0.0000e+00 - val_loss: 6.9630\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6810 - loss: 1.6815 - val_accuracy: 0.0000e+00 - val_loss: 7.0760\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7028 - loss: 1.5934 - val_accuracy: 0.0000e+00 - val_loss: 7.2708\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6273 - loss: 1.5852 - val_accuracy: 0.0000e+00 - val_loss: 7.1825\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6637 - loss: 1.5188 - val_accuracy: 0.0000e+00 - val_loss: 7.2164\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7509 - loss: 1.4462 - val_accuracy: 0.0000e+00 - val_loss: 7.3228\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7297 - loss: 1.3966 - val_accuracy: 0.0000e+00 - val_loss: 7.4294\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8355 - loss: 1.3776 - val_accuracy: 0.0000e+00 - val_loss: 7.4165\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8517 - loss: 1.3335 - val_accuracy: 0.0000e+00 - val_loss: 7.5308\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8081 - loss: 1.2895 - val_accuracy: 0.0000e+00 - val_loss: 7.5130\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8260 - loss: 1.2920 - val_accuracy: 0.0000e+00 - val_loss: 7.5632\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8836 - loss: 1.2456 - val_accuracy: 0.0000e+00 - val_loss: 7.6493\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8573 - loss: 1.1549 - val_accuracy: 0.0000e+00 - val_loss: 7.6358\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8836 - loss: 1.1393 - val_accuracy: 0.0000e+00 - val_loss: 7.6909\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9054 - loss: 1.0931 - val_accuracy: 0.0000e+00 - val_loss: 7.7373\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9194 - loss: 1.0649 - val_accuracy: 0.0000e+00 - val_loss: 7.7474\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9239 - loss: 1.0596 - val_accuracy: 0.0000e+00 - val_loss: 7.8056\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9200 - loss: 0.9748 - val_accuracy: 0.0000e+00 - val_loss: 7.8012\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9496 - loss: 0.9906 - val_accuracy: 0.0000e+00 - val_loss: 7.8717\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9200 - loss: 0.9734 - val_accuracy: 0.0000e+00 - val_loss: 7.9160\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9138 - loss: 0.9641 - val_accuracy: 0.0000e+00 - val_loss: 7.9094\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9184 - loss: 0.9028 - val_accuracy: 0.0000e+00 - val_loss: 8.0183\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9519 - loss: 0.9336 - val_accuracy: 0.0000e+00 - val_loss: 7.9907\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9340 - loss: 0.8796 - val_accuracy: 0.0000e+00 - val_loss: 8.0492\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9737 - loss: 0.8328 - val_accuracy: 0.0476 - val_loss: 8.0473\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9720 - loss: 0.8595 - val_accuracy: 0.0476 - val_loss: 8.0141\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9821 - loss: 0.8066 - val_accuracy: 0.0476 - val_loss: 8.1264\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9798 - loss: 0.7637 - val_accuracy: 0.0476 - val_loss: 8.1390\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9821 - loss: 0.7942 - val_accuracy: 0.0476 - val_loss: 8.0827\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9821 - loss: 0.7181 - val_accuracy: 0.0476 - val_loss: 8.2100\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9899 - loss: 0.7373 - val_accuracy: 0.0476 - val_loss: 8.1184\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9837 - loss: 0.6786 - val_accuracy: 0.0476 - val_loss: 8.2183\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.9821 - loss: 0.7145 - val_accuracy: 0.0476 - val_loss: 8.2662\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.6900 - val_accuracy: 0.0476 - val_loss: 8.3473\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 0.0476 - val_loss: 8.2314\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.6883 - val_accuracy: 0.0476 - val_loss: 8.3991\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.6533 - val_accuracy: 0.0476 - val_loss: 8.3612\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.5860 - val_accuracy: 0.0476 - val_loss: 8.4253\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.5867 - val_accuracy: 0.0476 - val_loss: 8.3968\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.5880 - val_accuracy: 0.0476 - val_loss: 8.5265\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.6157 - val_accuracy: 0.0476 - val_loss: 8.4335\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.5684 - val_accuracy: 0.0476 - val_loss: 8.5788\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.5814 - val_accuracy: 0.0476 - val_loss: 8.5103\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9821 - loss: 0.5588 - val_accuracy: 0.0476 - val_loss: 8.5665\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9899 - loss: 0.5632 - val_accuracy: 0.0476 - val_loss: 8.5294\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.5455 - val_accuracy: 0.0476 - val_loss: 8.6404\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.4960 - val_accuracy: 0.0476 - val_loss: 8.6720\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.4751 - val_accuracy: 0.0476 - val_loss: 8.5848\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.4625 - val_accuracy: 0.0476 - val_loss: 8.6697\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.4424 - val_accuracy: 0.0476 - val_loss: 8.6573\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.4440 - val_accuracy: 0.0476 - val_loss: 8.6865\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.4407 - val_accuracy: 0.0476 - val_loss: 8.6790\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.4064 - val_accuracy: 0.0476 - val_loss: 8.6717\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.4510 - val_accuracy: 0.0476 - val_loss: 8.7820\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.4170 - val_accuracy: 0.0476 - val_loss: 8.7772\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.3868 - val_accuracy: 0.0476 - val_loss: 8.7590\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.3662 - val_accuracy: 0.0476 - val_loss: 8.7771\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.3624 - val_accuracy: 0.0476 - val_loss: 8.7686\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.3552 - val_accuracy: 0.0476 - val_loss: 8.8223\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.3562 - val_accuracy: 0.0476 - val_loss: 8.8685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "X3FrDLz5UDAa",
        "outputId": "9ab372e2-3592-42fb-ec17-18fa30b50a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m8,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)             │        \u001b[38;5;34m12,382\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,382</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m513,848\u001b[0m (1.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513,848</span> (1.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m171,282\u001b[0m (669.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">171,282</span> (669.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m342,566\u001b[0m (1.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,566</span> (1.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Test the model*"
      ],
      "metadata": {
        "id": "JG8DAXx3UGBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2= \"Data\"\n",
        "\n",
        "# Tokenizer\n",
        "token_text = tokenizer.texts_to_sequences([text2])[0]\n",
        "\n",
        "# Padding\n",
        "padded_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "# Predict\n",
        "predicted = model.predict(padded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdT63P_FcBGz",
        "outputId": "474bb560-7fce-46b4-9a72-ce3c5dc428d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgSucah9cwsy",
        "outputId": "29fc3b03-6eb2-46c2-e721-ec83533078ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.10959983e-05, 1.28434986e-04, 1.93160519e-01, 1.34249628e-01,\n",
              "        2.48359353e-03, 1.39928624e-01, 5.50409779e-02, 1.70170218e-01,\n",
              "        1.66222904e-04, 4.89087506e-05, 1.00370077e-03, 5.14242623e-04,\n",
              "        9.54321222e-05, 3.17834754e-04, 5.43840928e-04, 5.33401675e-04,\n",
              "        1.21122890e-03, 2.77114541e-05, 2.69305776e-04, 2.77052313e-04,\n",
              "        1.48135843e-02, 1.66900866e-02, 3.83977429e-03, 3.03897308e-04,\n",
              "        2.13171006e-04, 2.90307769e-04, 1.29129439e-05, 1.86316771e-04,\n",
              "        4.24639766e-05, 1.07719379e-05, 6.20197625e-06, 2.20925771e-02,\n",
              "        4.61700605e-03, 4.12560548e-05, 6.68598339e-04, 9.80787227e-05,\n",
              "        2.83038768e-04, 2.48467604e-05, 2.00805836e-04, 4.66855709e-05,\n",
              "        3.00779473e-02, 2.10966114e-02, 3.08988565e-05, 4.18333858e-02,\n",
              "        1.61782373e-02, 4.38339950e-04, 1.43750331e-05, 9.63398779e-05,\n",
              "        2.28187142e-04, 7.78836766e-05, 9.56284057e-05, 2.73681089e-05,\n",
              "        4.91993087e-05, 1.15188232e-04, 1.03923558e-04, 3.23868808e-05,\n",
              "        1.19894091e-02, 1.70949823e-03, 8.30291014e-04, 4.11359360e-04,\n",
              "        4.22679768e-05, 2.86127673e-04, 1.44005957e-04, 1.17168827e-04,\n",
              "        1.01258098e-04, 1.86982856e-04, 8.38022534e-05, 1.38559786e-04,\n",
              "        6.64449472e-05, 9.98678952e-05, 9.50467802e-06, 3.96332071e-05,\n",
              "        1.03584722e-01, 1.40975180e-05, 3.92445305e-04, 3.38342553e-03,\n",
              "        3.53571304e-05, 5.11326070e-04, 2.54245009e-04, 2.41540343e-04,\n",
              "        1.04948405e-04, 3.14164645e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qt6xxkFc1FG",
        "outputId": "1e0a3237-463d-4c1b-918e-c458e46490cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk_3HbuWdAQS",
        "outputId": "032c078b-7157-4cc2-bbc5-239ec3bbe607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'data': 2,\n",
              " 'analysis': 3,\n",
              " 'a': 4,\n",
              " 'the': 5,\n",
              " 'can': 6,\n",
              " 'is': 7,\n",
              " \"it's\": 8,\n",
              " 'organizations': 9,\n",
              " 'to': 10,\n",
              " 'make': 11,\n",
              " 'informed': 12,\n",
              " 'decisions': 13,\n",
              " 'predict': 14,\n",
              " 'improve': 15,\n",
              " 'company': 16,\n",
              " 'through': 17,\n",
              " 'customer': 18,\n",
              " 'strategies': 19,\n",
              " 'healthcare': 20,\n",
              " 'not': 21,\n",
              " 'just': 22,\n",
              " 'mere': 23,\n",
              " 'process': 24,\n",
              " 'tool': 25,\n",
              " 'that': 26,\n",
              " 'empowers': 27,\n",
              " 'trends': 28,\n",
              " 'operational': 29,\n",
              " 'efficiency': 30,\n",
              " 'backbone': 31,\n",
              " 'of': 32,\n",
              " 'strategic': 33,\n",
              " 'planning': 34,\n",
              " 'in': 35,\n",
              " 'businesses': 36,\n",
              " 'governments': 37,\n",
              " 'other': 38,\n",
              " 'consider': 39,\n",
              " 'some': 40,\n",
              " 'examples': 41,\n",
              " 'take': 42,\n",
              " 'for': 43,\n",
              " 'instance': 44,\n",
              " 'leading': 45,\n",
              " 'e': 46,\n",
              " 'commerce': 47,\n",
              " 'understand': 48,\n",
              " 'their': 49,\n",
              " \"customers'\": 50,\n",
              " 'buying': 51,\n",
              " 'behavior': 52,\n",
              " 'preferences': 53,\n",
              " 'patterns': 54,\n",
              " 'they': 55,\n",
              " 'then': 56,\n",
              " 'use': 57,\n",
              " 'this': 58,\n",
              " 'information': 59,\n",
              " 'personalize': 60,\n",
              " 'experiences': 61,\n",
              " 'forecast': 62,\n",
              " 'sales': 63,\n",
              " 'optimize': 64,\n",
              " 'marketing': 65,\n",
              " 'ultimately': 66,\n",
              " 'driving': 67,\n",
              " 'business': 68,\n",
              " 'growth': 69,\n",
              " 'satisfaction': 70,\n",
              " 'another': 71,\n",
              " 'good': 72,\n",
              " 'example': 73,\n",
              " 'industry': 74,\n",
              " 'providers': 75,\n",
              " 'disease': 76,\n",
              " 'outbreaks': 77,\n",
              " 'patient': 78,\n",
              " 'care': 79,\n",
              " 'about': 80,\n",
              " 'treatment': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == np.argmax(predicted):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqQbe-p-dTv5",
        "outputId": "dd5992a0-5168-4517-fece-71c5c95843c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3= \"Data analysis is not just a mere process it's a tool\"\n",
        "\n",
        "# Tokenizer\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "\n",
        "# Padding\n",
        "padded_text = pad_sequences([token_text3], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "# Predict\n",
        "predicted = model.predict(padded_text)\n",
        "\n",
        "pos = np.argmax(predicted)\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == np.argmax(predicted):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNwSUQOHeCv5",
        "outputId": "15201458-b1db-4a64-c4dd-f7c527d81fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "tool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Improvements:\n",
        "1. Increasing the LSTM units\n",
        "2. Increasing the Dense layers\n",
        "3. Increasing the Data\n",
        "4. Using a pre-treained model on larger corpus of data\n",
        "5. Hyper parameter optimization"
      ],
      "metadata": {
        "id": "RPIJfyMffb9K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00VQ2Qtugq31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}